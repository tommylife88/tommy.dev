[{"content":"AGL（Automotive Grade Linux）やってみた。\n#0_Getting_Started/1_Quickstart/Using_Ready_Made_Images/\nのx86 (Emulation and Hardware)をやってみた。\n試した環境 1 2 3 4 5 6 7 8 9  # Distro $ cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=20.04 DISTRIB_CODENAME=focal DISTRIB_DESCRIPTION=\u0026#34;Ubuntu 20.04.2 LTS\u0026#34; # Kernel $ uname -a Linux XXX 5.8.0-53-generic #60~20.04.1-Ubuntu SMP Thu May 6 09:52:46 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux   手順 手順は、kvmという仮想化機構の利用を前提していて、ホストPCのCPUに仮想化支援機構が組み込まれているかによって実行手順・結果が変わってくるかも。\nそう古くないCPUでCore i3以上なら気にしなくて良いかと。\n確認する場合、/proc/cpuinfoにvmxというフラグが存在していればOKなはず。\n1  $ cat /proc/cpuinfo | grep vmx   また、公式のやり方は、agl-demoの仮想イメージをqemuというアプリケーションで起動して、そこにVNC（vinagre）でリモートログインする方法。\nVNCを介さないやり方で実施してみた。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  # homeフォルダに移動（特に決まりはない） $ cd ~ # エミュレータをインストール $ sudo apt install qemu # qemuからx86_64用Linuxカーネル起動するためのパッケージをインストール $ sudo apt install qemu-system-x86 # 作業フォルダ作成 \u0026amp; 作業フォルダに移動 $ mkdir agl-demo \u0026amp;\u0026amp; cd $_ # agl-demoの仮想イメージ取得 $ wget https://download.automotivelinux.org/AGL/snapshots/master/latest/qemux86-64/deploy/images/qemux86-64/agl-demo-platform-crosssdk-qemux86-64.ext4.xz # qemuのカーネルイメージ取得 $ wget https://download.automotivelinux.org/AGL/snapshots/master/latest/qemux86-64/deploy/images/qemux86-64/bzImage # agl-demoの仮想イメージを解凍 $ xz -v -d agl-demo-platform-crosssdk-qemux86-64.ext4.xz # agl-demoの仮想イメージを指定してqemuを起動 $ sudo qemu-system-x86_64 \\ -device virtio-net-pci,netdev=net0,mac=52:54:00:12:35:02 \\ -cpu kvm64 \\ -cpu qemu64,+ssse3,+sse4.1,+sse4.2,+popcnt \\ -enable-kvm \\ -m 2048 \\ -netdev user,id=net0,hostfwd=tcp::2222-:22 \\ -drive file=agl-demo-platform-crosssdk-qemux86-64.ext4,if=virtio,format=raw \\ -show-cursor \\ -usb \\ -vga virtio \\ -soundhw hda \\ -machine q35 \\ -serial mon:vc \\ -serial mon:stdio \\ -serial null \\ -kernel bzImage \\ -snapshot \\ -append \u0026#39;root=/dev/vda rw console=tty0 mem=2048M ip=dhcp oprofile.timer=1 console=ttyS0,115200n8 verbose fstab=no\u0026#39;   しばらくするとdemo画面が表示された。\nスクリーンが横回転になっているのでこれは設定か何かかな。\nコンソールは以下（rootユーザー／パスワード無し）でログインできる。\n1 2  Automotive Grade Linux 11.91.0+snapshot qemux86-64 ttyS1 qemux86-64 login: root   シャットダウンするときは\n1  qemux86-64 login: poweroff   このとき、作業内容は消える。\n作業内容を保持したければ-snapshot \\を削除してqemuを起動すれば良さそう。\nWindouws on VirtualBoxも対応されている 試してはいないが、WindowsでもVirualBox上で動作可能みたい。\n#0_Getting_Started/1_Quickstart/Using_Ready_Made_Images/#2-virtual-box-emulation\n参考  Automotive Grade Linuxことはじめ  ","description":"","id":0,"section":"posts","tags":["AGL","Ubuntu","Linux"],"title":"AGL（Automotive Grade Linux）ことはじめ","uri":"https://tommylife88.github.io/tommy.dev/posts/2021-06-15-agl-demo/"},{"content":"チームでVSCodeで開発するときに、「この拡張機能は入れておけ」ってあると思う。\nそんな時、VSCodeでお勧めの拡張機能に出す出さないを.vscode/extensions.jsonで管理できる。\nリポジトリで管理できるので便利。\nただし、拡張機能でも信頼できないものもあるので、チーム以外のリポジトリ（よくわからないもの）の.vscode/extensions.jsonはちゃんと拡張機能の評価を見てからにしましょう。\nこの機能は勝手にローカルにインストールするものでは無いのでそこは最終的に自己責任になる。\nhttps://qiita.com/Glavis/items/c3dac07e4bcf5c50db0a\n1 2 3 4 5 6 7 8 9 10 11 12 13  { // See https://go.microsoft.com/fwlink/?LinkId=827846 to learn about workspace recommendations. // Extension identifier format: ${publisher}.${name}. Example: vscode.csharp // List of extensions which should be recommended for users of this workspace. \u0026#34;recommendations\u0026#34;: [ \u0026#34;EditorConfig.EditorConfig\u0026#34;, \u0026#34;dbaeumer.vscode-eslint\u0026#34;, \u0026#34;esbenp.prettier-vscode\u0026#34;, ], // List of extensions recommended by VS Code that should not be recommended for users of this workspace. \u0026#34;unwantedRecommendations\u0026#34;: [\u0026#34;ms-vscode.vscode-typescript-tslint-plugin\u0026#34;] }   ","description":"","id":1,"section":"posts","tags":["VSCode"],"title":"VSCodeでお勧めの拡張機能を共有する","uri":"https://tommylife88.github.io/tommy.dev/posts/2021-06-01-vscode-extensions/"},{"content":"from GitHub README\nEmbedded System engineer.\n 👀 I’m interested in web development \u0026hellip; 🌱 I’m currently learning React, TypeScript \u0026hellip; 🎶 ONE OK ROCK  My Skills Skill set\nLanguage       Middleware     Framework , Library      Tools        OS     GitHub Status \nCertifications Social \n","description":"Abount this site.","id":2,"section":"","tags":null,"title":"About","uri":"https://tommylife88.github.io/tommy.dev/about/"},{"content":"This article offers a sample of basic Markdown syntax that can be used in Hugo content files, also it shows whether basic HTML elements are decorated with CSS in a Hugo theme.\nHeadings The following HTML \u0026lt;h1\u0026gt;—\u0026lt;h6\u0026gt; elements represent six levels of section headings. \u0026lt;h1\u0026gt; is the highest section level while \u0026lt;h6\u0026gt; is the lowest.\nH1 H2 H3 H4 H5 H6 Paragraph Xerum, quo qui aut unt expliquam qui dolut labo. Aque venitatiusda cum, voluptionse latur sitiae dolessi aut parist aut dollo enim qui voluptate ma dolestendit peritin re plis aut quas inctum laceat est volestemque commosa as cus endigna tectur, offic to cor sequas etum rerum idem sintibus eiur? Quianimin porecus evelectur, cum que nis nust voloribus ratem aut omnimi, sitatur? Quiatem. Nam, omnis sum am facea corem alique molestrunt et eos evelece arcillit ut aut eos eos nus, sin conecerem erum fuga. Ri oditatquam, ad quibus unda veliamenimin cusam et facea ipsamus es exerum sitate dolores editium rerore eost, temped molorro ratiae volorro te reribus dolorer sperchicium faceata tiustia prat.\nItatur? Quiatae cullecum rem ent aut odis in re eossequodi nonsequ idebis ne sapicia is sinveli squiatum, core et que aut hariosam ex eat.\nBlockquotes The blockquote element represents content that is quoted from another source, optionally with a citation which must be within a footer or cite element, and optionally with in-line changes such as annotations and abbreviations.\nBlockquote without attribution  Tiam, ad mint andaepu dandae nostion secatur sequo quae.\nNote that you can use Markdown syntax within a blockquote.\n Blockquote with attribution  Don\u0026rsquo;t communicate by sharing memory, share memory by communicating.\n— Rob Pike1\n Tables Tables aren\u0026rsquo;t part of the core Markdown spec, but Hugo supports supports them out-of-the-box.\n   Name Age     Bob 27   Alice 23    Inline Markdown within tables    Inline  Markdown  In  Table     italics bold strikethrough  code    Code Blocks Code block with backticks html \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt; Code block indented with four spaces \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026quot;en\u0026quot;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026quot;UTF-8\u0026quot;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;  Code block with Hugo\u0026rsquo;s internal highlight shortcode 1 2 3 4 5 6 7 8 9 10  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;UTF-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Example HTML5 Document\u0026lt;/title\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;p\u0026gt;Test\u0026lt;/p\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   List Types Ordered List  First item Second item Third item  Unordered List  List item Another item And another item  Nested list  Item   First Sub-item Second Sub-item  Other Elements — abbr, sub, sup, kbd, mark GIF is a bitmap image format.\nH2O\nXn + Yn: Zn\nPress CTRL+ALT+Delete to end the session.\nMost salamanders are nocturnal, and hunt for insects, worms, and other small creatures.\n The above quote is excerpted from Rob Pike\u0026rsquo;s talk during Gopherfest, November 18, 2015.\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n  ","description":"Sample article showcasing basic Markdown syntax and formatting for HTML elements.","id":3,"section":"posts","tags":["markdown","demo"],"title":"Markdown Syntax Guide","uri":"https://tommylife88.github.io/tommy.dev/posts/demo-markdown-syntax/"},{"content":"Code Syntax Highlighting Verify the following code blocks render as code blocks and highlight properly.\nMore about tuning syntax highlighting is the Hugo documentation.\nDiff 1 2 3 4 5 6 7 8 9 10  *** /path/to/original\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; --- /path/to/new\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line   *** /path/to/original\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; --- /path/to/new\t\u0026#39;\u0026#39;timestamp\u0026#39;\u0026#39; *************** *** 1 **** ! This is a line. --- 1 --- ! This is a replacement line. It is important to spell -removed line +new line Makefile CC=gcc CFLAGS=-I. hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I. 1 2 3 4 5  CC=gcc CFLAGS=-I. hellomake: hellomake.o hellofunc.o $(CC) -o hellomake hellomake.o hellofunc.o -I.   JSON 1 2 3  {\u0026#34;employees\u0026#34;:[ {\u0026#34;firstName\u0026#34;:\u0026#34;John\u0026#34;, \u0026#34;lastName\u0026#34;:\u0026#34;Doe\u0026#34;}, ]}   Markdown 1 2 3  **bold** *italics* [link](www.example.com)   JavaScript 1  document.write(\u0026#39;Hello, world!\u0026#39;);   CSS 1 2 3  body { background-color: red; }   Objective C 1 2 3 4 5 6  #import \u0026lt;stdio.h\u0026gt;  int main (void) { printf (\u0026#34;Hello world!\\n\u0026#34;); }   Python 1  print \u0026#34;Hello, world!\u0026#34;   XML 1 2 3 4 5  \u0026lt;employees\u0026gt; \u0026lt;employee\u0026gt; \u0026lt;firstName\u0026gt;John\u0026lt;/firstName\u0026gt; \u0026lt;lastName\u0026gt;Doe\u0026lt;/lastName\u0026gt; \u0026lt;/employee\u0026gt; \u0026lt;/employees\u0026gt;   Perl 1  print \u0026#34;Hello, World!\\n\u0026#34;;   Bash 1  echo \u0026#34;Hello World\u0026#34;   PHP 1  \u0026lt;?php echo \u0026#39;\u0026lt;p\u0026gt;Hello World\u0026lt;/p\u0026gt;\u0026#39;; ?\u0026gt;  CoffeeScript 1  console.log(“Hello world!”);   C# 1 2 3 4 5 6 7 8  using System; class Program { public static void Main(string[] args) { Console.WriteLine(\u0026#34;Hello, world!\u0026#34;); } }   C++ 1 2 3 4 5 6 7  #include \u0026lt;iostream.h\u0026gt; main() { cout \u0026lt;\u0026lt; \u0026#34;Hello World!\u0026#34;; return 0; }   SQL 1 2  SELECTcolumn_name,column_nameFROMtable_name;  Go 1 2 3 4 5  package main import \u0026#34;fmt\u0026#34; func main() { fmt.Println(\u0026#34;Hello, 世界\u0026#34;) }   Ruby 1  puts \u0026#34;Hello, world!\u0026#34;   Java 1 2 3 4 5 6 7 8 9 10 11 12  import javax.swing.JFrame; //Importing class JFrame import javax.swing.JLabel; //Importing class JLabel public class HelloWorld { public static void main(String[] args) { JFrame frame = new JFrame(); //Creating frame  frame.setTitle(\u0026#34;Hi!\u0026#34;); //Setting title frame  frame.add(new JLabel(\u0026#34;Hello, world!\u0026#34;));//Adding text to frame  frame.pack(); //Setting size to smallest  frame.setLocationRelativeTo(null); //Centering frame  frame.setVisible(true); //Showing frame  } }   Latex Equation 1  \\frac{d}{dx}\\left( \\int_{0}^{x} f(u)\\,du\\right)=f(x).   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  import {x, y} as p from \u0026#39;point\u0026#39;; const ANSWER = 42; class Car extends Vehicle { constructor(speed, cost) { super(speed); var c = Symbol(\u0026#39;cost\u0026#39;); this[c] = cost; this.intro = `This is a car runs at ${speed}.`; } } for (let num of [1, 2, 3]) { console.log(num + 0b111110111); } function $initHighlight(block, flags) { try { if (block.className.search(/\\bno\\-highlight\\b/) != -1) return processBlock(block.function, true, 0x0F) + \u0026#39; class=\u0026#34;\u0026#34;\u0026#39;; } catch (e) { /* handle exception */ var e4x = \u0026lt;div\u0026gt;Example \u0026lt;p\u0026gt;1234\u0026lt;/p\u0026gt;\u0026lt;/div\u0026gt;; } for (var i = 0 / 2; i \u0026lt; classes.length; i++) { // \u0026#34;0 / 2\u0026#34; should not be parsed as regexp  if (checkCondition(classes[i]) === undefined) return /\\d+[\\s/]/g; } console.log(Array.every(classes, Boolean)); } export $initHighlight;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  \u0026lt;!DOCTYPE html\u0026gt; \u0026lt;html lang=\u0026#34;en\u0026#34;\u0026gt; \u0026lt;head\u0026gt; \u0026lt;meta charset=\u0026#34;utf-8\u0026#34;\u0026gt; \u0026lt;title\u0026gt;Hello world\u0026lt;/title\u0026gt; \u0026lt;link href=\u0026#39;http://fonts.googleapis.com/css?family=Roboto:400,400italic,700,700italic\u0026#39; rel=\u0026#39;stylesheet\u0026#39; type=\u0026#39;text/css\u0026#39;\u0026gt; \u0026lt;link rel=\u0026#34;stylesheet\u0026#34; href=\u0026#34;index.css\u0026#34; /\u0026gt; \u0026lt;/head\u0026gt; \u0026lt;body\u0026gt; \u0026lt;div id=\u0026#34;app\u0026#34;\u0026gt;\u0026lt;/div\u0026gt; \u0026lt;script src=\u0026#34;//cdnjs.cloudflare.com/ajax/libs/less.js/2.5.1/less.min.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;vendor/prism.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;script src=\u0026#34;examples.bundle.js\u0026#34;\u0026gt;\u0026lt;/script\u0026gt; \u0026lt;/body\u0026gt; \u0026lt;/html\u0026gt;   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41  /********************************************************* * General */ pre[class*=\u0026#34;language-\u0026#34;], code { color: #5c6e74; font-size: 13px; text-shadow: none; font-family: Consolas, Monaco, \u0026#39;Andale Mono\u0026#39;, \u0026#39;Ubuntu Mono\u0026#39;, monospace; direction: ltr; text-align: left; white-space: pre; word-spacing: normal; word-break: normal; line-height: 1.5; tab-size: 4; hyphens: none; } pre[class*=\u0026#34;language-\u0026#34;]::selection, code::selection { text-shadow: none; background: #b3d4fc; } @media print { pre[class*=\u0026#34;language-\u0026#34;], code { text-shadow: none; } } pre[class*=\u0026#34;language-\u0026#34;] { padding: 1em; margin: .5em 0; overflow: auto; background: #f8f5ec; } :not(pre) \u0026gt; code { padding: .1em .3em; border-radius: .3em; color: #db4c69; background: #f9f2f4; }   ","description":"Syntax highlighting test","id":4,"section":"posts","tags":["demo"],"title":"Syntax highlighting","uri":"https://tommylife88.github.io/tommy.dev/posts/demo-syntax-highlight/"},{"content":"Jenkinsサーバーのビルド環境をクリーンに保ちたいのでDockerコンテナでCIを回したい。\nその環境作成メモ。\nっていうか、これやるなら、GitLab CI/CD、GitHub Actionsの方が簡単だけど。（Jesnkinsおじさんとはもうおさらば）\n要件など Docker outside of Docker（DooD）したい。\n Jenkins本体はDockerコンテナ上で実行される Jenkinsのビルドジョブ時のDocker操作はホストに接続され、ホスト環境にコンテナを作成する（DooD） セキュリティの観点から、Dockerを操作するユーザーをroot以外（jenkins）で作成する  dockerグループをホスト側のDockerグループIDで作成する jenkinsユーザーをdockerグループに所属させ、ホストのDockerへの操作権限を与える    ホスト環境 JenkinsをDockerするホストの環境。\n1 2 3 4 5 6 7 8  $ uname -srv Linux 5.8.0-40-generic #45~20.04.1-Ubuntu SMP Fri Jan 15 11:35:04 UTC 2021 $ cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=20.04 DISTRIB_CODENAME=focal DISTRIB_DESCRIPTION=\u0026#34;Ubuntu 20.04.2 LTS\u0026#34;   dockerコンテナのイメージ一覧。\n後でJenkins上のビルドジョブからdocker imagesして同じ結果が表示されればOK。\n1 2 3 4 5 6  $ docker --version Docker version 19.03.8, build afacb8b7f0 $ docker images REPOSITORY TAG IMAGE ID CREATED SIZE gcc latest e4aa98dc41ec 5 weeks ago 1.19GB docker/getting-started latest 3c156928aeec 10 months ago 24.8MB   構築してみた 構築した環境はGitHubにあげています。\nhttps://github.com/tommylife88/jenkins-dood\n簡単な解説 ホストのDockerグループIDをCOMPOSE内で使用するための環境変数を記載した設定ファイル。\n1  DOCKER_GROUP_ID=1001   docker-composeの設定ファイル。\nポートフォワードやJAVA_OPTSは好きなようにカスタマイズして良いが、肝はvolumesで/var/run/docker.sock:/var/run/docker.sockしているところ。このマウントを行うことでJenkinsからホストのDockerに接続できる。\ndocker-composeの設定まわりは、公式見よう。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  version:\u0026#39;2\u0026#39;services:jenkins:container_name:\u0026#34;jenkins-dood\u0026#34;build:context:./args:- DOCKER_GROUP_ID_HOST=${DOCKER_GROUP_ID}environment:- JAVA_OPTS=-Duser.timezone=Asia/Tokyo -Dfile.encoding=UTF-8 -Dsun.jnu.encoding=UTF-8ports:- 8080:8080volumes:- ./jenkins-data:/var/jenkins_home- /var/run/docker.sock:/var/run/docker.sock# mount docker.sock on host  Jenkins DooD環境構築用のDockerfile。特に難しいことはしていないはず。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  FROMjenkins/jenkins:ltsUSERroot# add jenkins userRUN mkdir /home/jenkins \u0026amp;\u0026amp; chown jenkins:jenkins /home/jenkins \u0026amp;\u0026amp; usermod -d /home/jenkins jenkins# add docker groupARG DOCKER_GROUP_ID_HOSTRUN groupadd -g ${DOCKER_GROUP_ID_HOST} docker \u0026amp;\u0026amp; usermod -aG docker jenkins# install docker, docker-composeENV DOCKER_VERSION 20.10.0RUN curl -fL -o docker.tgz \u0026#34;https://download.docker.com/linux/static/test/x86_64/docker-$DOCKER_VERSION.tgz\u0026#34; \u0026amp;\u0026amp; \\  tar --strip-component=1 -xvaf docker.tgz -C /usr/binENV DOCKER_COMPOSE_VERSION 1.28.4RUN curl -L https://github.com/docker/compose/releases/download/${DOCKER_COMPOSE_VERSION}/docker-compose-`uname -s`-`uname -m` \u0026gt; /usr/local/bin/docker-compose \u0026amp;\u0026amp; chmod +x /usr/local/bin/docker-composeUSERjenkins  動作確認 Jenkinsのビルドジョブを作成、シェルスクリプトでdocker imagesしてみた結果。\n最後のdocker imagesでホストのDocker環境に接続されている様子が分かる。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  Running as SYSTEM Building in workspace /var/jenkins_home/workspace/dood [dood] $ /bin/sh -xe /tmp/jenkins3072304799133685752.sh + docker --version Docker version 20.10.0, build 7287ab3 + docker run hello-world Hello from Docker! This message shows that your installation appears to be working correctly. To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \u0026#34;hello-world\u0026#34; image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal. To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bash Share images, automate workflows, and more with a free Docker ID: https://hub.docker.com/ For more examples and ideas, visit: https://docs.docker.com/get-started/ + docker images REPOSITORY TAG IMAGE ID CREATED SIZE jenkins-dood_jenkins latest 4b69f7a5d92f About an hour ago 877MB jenkins/jenkins lts 3f6389c017cc 13 days ago 566MB gcc latest e4aa98dc41ec 6 weeks ago 1.19GB docker/getting-started latest 3c156928aeec 10 months ago 24.8MB hello-world latest bf756fb1ae65 13 months ago 13.3kB Finished: SUCCESS   Docker Pipeline プラグイン Docker Pipelineプラグインを使っても同じ。\nJenkinsのパイプラインジョブで以下のような構成のパイプラインを設定する。\n（ホストにあるgccイメージからコンテナを作成しバージョンを表示するだけ）\npipeline { agent { docker { image 'gcc' } } stages { stage('Test') { steps { sh 'gcc --version' } } } } 実行した結果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  Running in Durability level: MAX_SURVIVABILITY [Pipeline] Start of Pipeline [Pipeline] node Running on Jenkins in /var/jenkins_home/workspace/dood-on-pipeline [Pipeline] { [Pipeline] isUnix [Pipeline] sh + docker inspect -f . gcc . [Pipeline] withDockerContainer Jenkins seems to be running inside container 088af532f126104ee3d55483f61105735e282b73383c8d1040a97a9b6300f723 $ docker run -t -d -u 1000:1000 -w /var/jenkins_home/workspace/dood-on-pipeline --volumes-from 088af532f126104ee3d55483f61105735e282b73383c8d1040a97a9b6300f723 -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** -e ******** gcc cat $ docker top aa54c31546bb4b3a7b5876ce9145c1ee80eef828c3ec0659cb1a95410568ef28 -eo pid,comm [Pipeline] { [Pipeline] stage [Pipeline] { (Test) [Pipeline] sh + gcc --version gcc (GCC) 10.2.0 Copyright (C) 2020 Free Software Foundation, Inc. This is free software; see the source for copying conditions. There is NO warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. [Pipeline] } [Pipeline] // stage [Pipeline] } $ docker stop --time=1 aa54c31546bb4b3a7b5876ce9145c1ee80eef828c3ec0659cb1a95410568ef28 $ docker rm -f aa54c31546bb4b3a7b5876ce9145c1ee80eef828c3ec0659cb1a95410568ef28 [Pipeline] // withDockerContainer [Pipeline] } [Pipeline] // node [Pipeline] End of Pipeline Finished: SUCCESS   問題なさそう。\nただ、GitLab CI/CDとかに慣れると、Jenkinsのパイプライン設定はとっつきにくい。\n","description":"","id":5,"section":"posts","tags":["Jenkins","Docker"],"title":"Docker上のJenkinsからホストのDockerを使う（DooD）","uri":"https://tommylife88.github.io/tommy.dev/posts/2020-08-29-jenkins-dood/"},{"content":"NTPでサーバーの時刻合わせ【Ubuntu 18.04】 NTPは「Network Time Protocol」の略で、ネットワーク上でクライアントがサーバーに対して時刻を問い合わせるためのプロトコルです。\nNTPによって時刻が正確に保たれるので、保守面からもサーバーにインストールしておいて損はないでしょう。\nUbuntuであればインストールから設定まで簡単に導入出来ます。\n1 2  $ sudo apt -y install ntp $ sudo vi /etc/ntp.conf   /etc/ntp.confに自身のタイムゾーンのNTPサーバーを追記します。デフォルトはコメントアウトします。\n/etc/ntp.conf\n1 2 3 4 5 6 7 8 9 10 11 12  #pool 0.ubuntu.pool.ntp.org iburst #pool 1.ubuntu.pool.ntp.org iburst #pool 2.ubuntu.pool.ntp.org iburst #pool 3.ubuntu.pool.ntp.org iburst # Use Ubuntu\u0026#39;s ntp server as a fallback. #pool ntp.ubuntu.com server ntp.nict.jp iburst server ntp1.jst.mfeed.ad.jp iburst server ntp2.jst.mfeed.ad.jp iburst server ntp3.jst.mfeed.ad.jp iburst   NTPサーバーは、\n 立行政法人情報通信研究機構(NICT)の公開NTPサーバー インターネットマルチフィード(MFEED) 時刻情報提供サービス for Public  としました。\n正確な時間を得るためには「サーバー間の物理的な距離」も大事です。日本国内の有名どころを選んでみました。\nNTPを再起動して動作確認します。\n1 2 3 4 5 6 7 8  $ sudo systemctl restart ntp $ ntpq -p remote refid st t when poll reach delay offset jitter ============================================================================== *ntp-b2.nict.go. .NICT. 1 u 21 64 3 23.464 2.820 21.957 +ntp1.jst.mfeed. 133.243.236.17 2 u 22 64 3 24.403 1.069 3.885 +ntp2.jst.mfeed. 133.243.236.17 2 u 17 64 3 26.187 2.418 3.868 +ntp3.jst.mfeed. 133.243.236.17 2 u 21 64 3 24.008 3.610 4.740   左端の「*」は現在同期を行っているサーバー、「+」は次に同期行う候補のサーバーを表しています。\n時刻同期が安定してくると、「poll」で表示される間隔が長くなっていきます。最大1024秒で時刻問い合わせを行うようになりますので、勝手にシステムへの負荷が少なくなるようになっていきます。\n","description":"","id":6,"section":"posts","tags":["ntp","Ubuntu"],"title":"NTPでサーバーの時刻合わせ【Ubuntu 18.04】","uri":"https://tommylife88.github.io/tommy.dev/posts/2020-02-09-ntp-on-ubuntu1804/"},{"content":"Redmine 4.0をUbuntu 18.04 LTS Serverにインストールする手順\nで構築したRedmineをアップデート／バージョンアップする。\nアップデート準備 まずは、 http://redmine.jp/redmine_today/ からRedmineの最新情報を確認しておく。\n必ず、\n 最新バージョンが動作環境を満たしていることも確認しておく アップデート作業に入る前に必ずデータベース、およびアップロードしているファイルのバックアップをとっておく  こと。\nアップデートは基本的に、 http://guide.redmine.jp/RedmineUpgrade/ の公式の手順に従うだけ。\nアップデート RedmineはSVNリポジトリからチェックアウトしてる前提。\n1 2 3 4 5 6 7 8 9 10 11 12 13  # Redmineのインストールディレクトに移動（自分の環境に合わせて） cd /var/www/redmine # SVNチェックアウトのアップグレード sudo -u www-data svn update # 必要なgemを更新 sudo -u www-data bundle update # データベースの更新 sudo -u www-data RAILS_ENV=production bundle exec rake db:migrate sudo -u www-data RAILS_ENV=production bundle exec rake redmine:plugins:migrate # キャッシュのクリア sudo -u www-data RAILS_ENV=production bundle exec rake tmp:cache:clear # apacheの再起動 sudo systemctl restart apache2   最後に、Redmineサイトに管理者権限でログインして「管理」→「ロールと権限」画面を開き、Redmineのバージョンを確認して、一通り動作確認を行う。\n","description":"","id":7,"section":"posts","tags":["Redmine","Ubuntu"],"title":"Redmineをアップデートする手順（Ubuntu 18.04 LTS Server）","uri":"https://tommylife88.github.io/tommy.dev/posts/2020-01-20-update-redmine-on-ubuntu1804/"},{"content":"最小構成でインストールしたUbuntu 18.04.1 LTS ServerにRedmine 4.0をインストールする手順を残しておく。\nUbuntuのLTSの最新は20.04だが、Redmineの依存ライブラリ（Ruby等）がUbuntuの標準パッケージのものは新しすぎて環境整備が大変。\n現時点では18.04が楽と思われる。（Redmineのバージョンアップに期待） 要件は公式を確認しておこう。\nhttp://guide.redmine.jp/RedmineInstall/\nサーバー環境 Redmine以外は基本的にOS標準のパッケージで足りていることを想定しています。\n OS：Ubuntu 18.04.1 LTS Server Redmine：Redmine 4.0 stable データベース：MySQL 5.7.26 Webサーバー：Apache 2.4.18 (PassengerでRails実行) Ruby：2.5.1  OSの設定 OSインストール直後、パッケージの最新化、日本語設定。\n1 2 3 4 5 6  sudo locale-gen ja_JP.UTF-8 sudo update-locale LANG=ja_JP.UTF-8 sudo dpkg-reconfigure tzdata sudo apt update sudo apt upgrade -y sudo apt-get dist-upgrade   必要なパッケージをインストール 一応、Redmine 4.0に必要なRubyがOS標準で入手可能か確認する。公式によるとRedmine 4.0の場合、Ruby 2.2.2 以降、Rails 5.2が必須。\n1 2 3 4 5 6  sudo apt update apt-cache madison ruby #ruby | 1:2.5.1 | http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages sudo apt install ruby-dev ruby bundler apache2 libapache2-mod-passenger imagemagick libmagick++-dev subversion mysql-server libmysqlclient-dev #ruby -v ruby 2.5.1p57 (2018-03-29 revision 63029) [x86_64-linux-gnu]   MySQLの設定 文字コードの設定、ユーザーとデータベースの設定。\n1 2  sudo vi /etc/mysql/conf.d/redmine.cnf sudo chmod 644 /etc/mysql/conf.d/redmine.cnf   redmine.cnf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  [mysqld] innodb_file_format = Barracuda innodb_file_per_table = 1 innodb_large_prefix = 1 character-set-server = utf8mb4 skip-character-set-client-handshake collation-server = utf8mb4_general_ci init-connect = SET NAMES utf8mb4 [mysql] default-character-set = utf8mb4 [client] default-character-set = utf8mb4 [mysqldump] default-character-set = utf8mb4   mysql_secure_installationでrootユーザーのパスワード等、MySQLをインストールする。\n1 2 3  sudo mysql_secure_installation sudo service mysql restart sudo mysql -uroot -p   ここからMySQLのコマンドプロンプト上で。\nRedmine用のデータベースをredmineという名前で作成し、localhostのredmineというユーザー(パスワードmy_password)にredmineデータベースへのすべての権限を与えている。\n1 2 3  CREATE DATABASE redmine CHARACTER SET utf8mb4; CREATE USER \u0026#39;redmine\u0026#39;@\u0026#39;localhost\u0026#39; IDENTIFIED BY \u0026#39;my_password\u0026#39;; GRANT ALL PRIVILEGES ON redmine.* TO \u0026#39;redmine\u0026#39;@\u0026#39;localhost\u0026#39;;   Redmineの設定 Redmineアプリケーション実行用のフォルダを作成し、オーナーとグループをwww-dataに設定する。(apacheプロセスがRedmine環境のユーザーになるため、apacheプロセスへのアクセス権を与える)\n1 2 3 4  sudo mkdir -p /var/www/redmine sudo chown www-data:www-data /var/www/redmine sudo -u www-data svn co http://svn.redmine.org/redmine/branches/4.0-stable /var/www/redmine sudo -u www-data vi /var/www/redmine/config/database.yml   データベースの設定ファイルconfig/database.ymlを以下のように設定する。\n1 2 3 4 5 6 7 8 9 10 11  production:adapter:mysql2database:redminehost:localhostusername:redminepassword:\u0026#34;my_redmine\u0026#34;encoding:utf8mb4charset:utf8mb4collation:utf8mb4_general_cipool:\u0026lt;%= ENV.fetch(\u0026#34;RAILS_MAX_THREADS\u0026#34;) { 5 } %\u0026gt;socket:/var/run/mysqld/mysqld.sock  utf8mb4の有効化。\n1  sudo -u www-data vi /var/www/redmine/config/initializers/utf8mb4.rb   1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  module Utf8mb4 def create_table(table_name, options = {}) table_options = options.merge(options: \u0026#39;ENGINE=InnoDB ROW_FORMAT=DYNAMIC\u0026#39;) super(table_name, table_options) do |td| yield td if block_given? end end end ActiveSupport.on_load :active_record do module ActiveRecord::ConnectionAdapters class AbstractMysqlAdapter prepend Utf8mb4 end end end   Redmineのインストール RubyGemの依存解決と、データベース構築など。\n1 2 3 4 5 6 7 8  sudo chown -R www-data:www-data /var/www/redmine cd /var/www/redmine/ sudo gem update bundler sudo apt-get remove bundler # apt の bundler は要らなかった sudo -u www-data bundle install --without development test postgresql sqlite --path vendor/bundle sudo -u www-data bundle exec rake generate_secret_token sudo -u www-data RAILS_ENV=production bundle exec rake db:migrate sudo -u www-data RAILS_ENV=production REDMINE_LANG=ja bundle exec rake redmine:load_default_data   Apache連携 RedmineとApcheの連携。PassengerはApache上でRailsアプリを動かすもの。\nPassenger設定 1  sudo vi /etc/apache2/mods-available/passenger.conf   \u0026lt;IfModule mod_passenger.c\u0026gt; PassengerRoot /usr/lib/ruby/vendor_ruby/phusion_passenger/locations.ini PassengerDefaultRuby /usr/bin/ruby PassengerPreStart http://127.0.0.1:80/redmine/ \u0026lt;/IfModule\u0026gt; IPアドレスやポートは適宜変更する。\nRedmine設定 1  sudo vi /etc/apache2/sites-available/redmine.conf   /etc/apache2/sites-available/redmine.conf\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  listen 80 \u0026lt;VirtualHost *:80\u0026gt; ServerName redmine.com ServerAdmin redmine@redmine.com DocumentRoot /var/www/html RackBaseURI /redmine PassengerHighPerformance on \u0026lt;Directory /var/www/redmine/public\u0026gt; # Require ip ::1 127. 192.168. AllowOverride None Options None \u0026lt;/Directory\u0026gt; ErrorLog ${APACHE_LOG_DIR}/error.log CustomLog ${APACHE_LOG_DIR}/access.log combined \u0026lt;/VirtualHost\u0026gt; RailsEnv production RailsBaseURI /redmine   IPアドレスやポートは適宜変更する。\n1 2  sudo ln -s /var/www/redmine/public /var/www/html/redmine sudo a2ensite redmine   起動！ Apacheを再起動して運用開始！！\n1  sudo systemctl reload apache2   ブラウザからhttp://127.0.0.1:80/redmine/にアクセスしてRedmineのページが表示されれば作業完了です！\n","description":"","id":8,"section":"posts","tags":["Redmine","Ubuntu"],"title":"Redmine 4.0をUbuntu 18.04 LTS Serverにインストールする手順","uri":"https://tommylife88.github.io/tommy.dev/posts/2020-01-15-install-redmine-to-ubuntu1804/"},{"content":"Makefileって作るときはいろいろ調べながら作るけど、一度作るとそれ以上触ることないので、よく忘れる。備忘録も兼ねてテンプレとして残しておきます。\n全ての環境での動作を保証するものではない。使用する際は、環境に合わせて使う。 成果物はGitHubにプッシュ済み。\nhttps://github.com/tommylife88/makefile-template.git\nMakefileテンプレート 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77  # Makefile Template.  # . # |-- Makefile (This file) # |-- build # | `-- target file. # |-- obj # `-- object files. # |-- include # | `-- header files. # `-- source # `-- source files.  # Variables ## Directory defines BUILDDIR = ./build OBJDIR = $(BUILDDIR)/obj SRCDIR = ./source INCDIRS = ./include LIBDIRS = #-L ## Target name TARGET = $(BUILDDIR)/a.out ## Compiler options CC = gcc CFLAGS = -O2 -Wall CXX = g++ CXXFLAGS = -O2 -Wall LDFLAGS = SRCS := $(shell find $(SRCDIR) -name *.cpp -or -name *.c -or -name *.s) OBJS := $(SRCS:%=$(OBJDIR)/%.o) DEPS := $(OBJS:.o=.d) LIBS = #-lboost_system -lboost_thread INCLUDE := $(shell find $(INCDIRS) -type d) INCLUDE := $(addprefix -I,$(INCLUDE)) CPPFLAGS := $(INCLUDE) -MMD -MP LDFLAGS += $(LIBDIRS) $(LIBS) # Target default: make all all: $(TARGET) $(TARGET): $(OBJS) $(CXX) -o $@ $^ $(LDFLAGS) # assembly $(OBJDIR)/%.s.o: %.s $(MKDIR_P) $(dir $@) $(AS) $(ASFLAGS) -c $\u0026lt; -o $@ # c source $(OBJDIR)/%.c.o: %.c $(MKDIR_P) $(dir $@) $(CC) $(CPPFLAGS) $(CFLAGS) -c $\u0026lt; -o $@ # c++ source $(OBJDIR)/%.cpp.o: %.cpp $(MKDIR_P) $(dir $@) $(CXX) $(CPPFLAGS) $(CXXFLAGS) -c $\u0026lt; -o $@ .PHONY: all clean rebuild clean: $(RM) -r $(BUILDDIR) rebuild: make clean \u0026amp;\u0026amp; make -include $(DEPS) MKDIR_P = mkdir -p   ポイント out-of-source ビルド 本Makefileはout-of-sourceビルドとしています。buildディレクトリ直下に実行ファイル、build/objディレクトリにオブジェクトファイルと依存関係リストファイルを生成しています。\nout-of-sourceビルドする利点として、\n ソースディレクトリが汚れない cleanするときに楽  があります。\nヘッダファイルの依存関係の解決（-MMD、-MPオプション） Makefileの依存関係の記述の仕方によっては、ヘッダーファイルのみを編集した場合で、そのヘッダーファイルをインクルードしているソースファイルがコンパイルされないことがあります。しかもたちが悪いことにビルドが通ってしまう可能性もあるため致命的な欠陥になりかねないのです。\nこれは-MMDや-MPオプションで解決できます。\n -MMD … 依存関係にあるファイルリストを拡張子.dのファイルに保存しコンパイルを行う。 -MP … ヘッダーファイルを削除した場合、もともと依存関係にあるファイルはそのヘッダーファイルを探してしまいコンパイルが通らなくなる。本オプションは偽のターゲットを定義することで、削除されたはずのヘッダーファイルを探しても大丈夫なようにしてあげる。  1 2 3 4 5 6 7 8 9  （省略） SRCS := $(shell find $(SRCDIR) -name *.cpp -or -name *.c -or -name *.s) OBJS := $(SRCS:%=$(OBJDIR)/%.o) DEPS := $(OBJS:.o=.d) （省略） CPPFLAGS := $(INCLUDE) -MMD -MP （省略） -include $(DEPS) （省略）   本MakefileではDEPS変数に全オブジェクトファイルの依存ファイルである拡張子.dファイルを生成し、-include $(DEPS)で依存関係の解消を行っています。\n","description":"","id":9,"section":"posts","tags":["makefile","gcc"],"title":"Makefileテンプレート作った","uri":"https://tommylife88.github.io/tommy.dev/posts/2019-12-01-makefile-template/"},{"content":"Dockerレジストリを経由せず、Dockerイメージをファイルとして配布したい。\nコンテナをtarファイル化 docker export使う。\n1  $ docker export \u0026lt;container id\u0026gt; \u0026gt; docker_archive.tar   tarファイルからDockerイメージを作成 docker import使う。\n1  $ cat docker_archive.tar | docker import - hoge:latest   コンテナ起動 1  $ docker run -it hoge:latest   ","description":"","id":10,"section":"posts","tags":["Docker"],"title":"Dockerコンテナをエクスポート／インポートする","uri":"https://tommylife88.github.io/tommy.dev/posts/2019-11-22-export-docker-container/"},{"content":"dockerで起動しっぱなしのコンテナのログがディスクを圧迫していたので、ログを消去する方法と、ついでにログのローテーション設定を行った。\ndocker-composeでも同じ。\nログのクリア方法 まずは手動でログをクリアする方法から。\nデフォルトのロギングドライバは「json-file」 1 2  $ docker info | grep Logging Logging Driver: json-file   json-fileはコンテナの標準出力と標準エラーを/var/lib/docker/containers/[container-id]/[container-id]-json.log（環境に依存するかも）に出力するため起動しっぱなしだとディスクを圧迫する。\nログを手動で消去する 名前は適宜置き換えて。 まず起動しているコンテナの一覧を表示する。\n1 2 3 4 5  $ docker-compose ps Name Command State Ports --------------------------------------------------------------------------------------- XXXX_app_1 /docker-entrypoint.sh dock ... Up 0.0.0.0:3000-\u0026gt;3000/tcp …   ログを吐いてみる。\n$ docker logs XXXX_app_1 #大量のログが・・ コンテナのログの保存場所を調べる。\n1 2 3  $ docker inspect XXXX_app_1 | grep -i log \u0026#34;LogPath\u0026#34;: \u0026#34;/var/lib/docker/containers/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1-json.log\u0026#34;, \u0026#34;LogConfig\u0026#34;: {   （消去して問題ないかを確認した上で）ログを消去する。\nroot権限が必要かも。\n1  $ truncate -s 0 /var/lib/docker/containers/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1/bef1e7aa9c237a34a9ea08dfd5253c3621915bed2cfd65f7985580998607beb1-json.log   というか、docker logs cleanてきなコマンドはないのかね。\nログのローテート設定 次にローテーションさせる。\nグローバル設定で行う場合 dockerデーモンの設定ファイル/etc/docker/daemon.json（デフォルトの場所）にロギングドライバのオプションを書く。ファイルが無い場合は新規作成する。\nhttp://docs.docker.jp/engine/reference/commandline/dockerd.html#daemon-configuration-file\n1 2 3 4 5  $ cat /etc/docker/daemon.json { \u0026#34;log-driver\u0026#34;: \u0026#34;json-file\u0026#34;, \u0026#34;log-opts\u0026#34;: {\u0026#34;max-size\u0026#34;: \u0026#34;10m\u0026#34;, \u0026#34;max-file\u0026#34;: \u0026#34;3\u0026#34;} }   dockerデーモンを再起動する。\n1 2 3  $ docker-compose stop $ systemctl restart docker $ docker-compose start   設定は新しく作成したコンテナから適用される。 （構築済みのコンテナには反映されません）\ndocker run オプションで行う場合 docker runコマンドのオプションとして指定できる。\nhttp://docs.docker.jp/engine/reference/logging/overview.html#json\n1 2  --log-opt max-size=[0-9+][k|m|g] --log-opt max-file=[0-9]   1 2  $ docker run -d --log-opt max-size=1k --log-opt max-file=10 $ docker start --log-opt max-size=100m --log-opt max-file=10   docker-compose.yml で設定する場合 docker-composeでは\n1 2 3 4 5 6 7 8 9 10 11 12  mongo:image:mongo:3.4volumes:- mongo_configdb:/data/configdb- mongo_db:/data/db# add ↓↓↓logging:driver:\u0026#34;json-file\u0026#34;# defaults if not specifiedoptions:max-size:\u0026#34;10m\u0026#34;max-file:\u0026#34;3\u0026#34;# add ↑↑↑  と書くと設定される。\n構築済みのコンテナの場合は、docker-compose upでコンテナの再構築が必要。\n","description":"","id":11,"section":"posts","tags":["Docker"],"title":"Dockerコンテナのログのクリア方法とローテーション設定","uri":"https://tommylife88.github.io/tommy.dev/posts/2019-11-20-docker-log-rotation/"},{"content":"LPIC-3（304：仮想化とハイアベイラビリティ）試験を受けて、無事一発合格してきました。記念してどう対策してきたかを記事にしたいと思います。\nLPIC-2（201,202）は合格済みです。\nLPICを取ろうと思った経緯など 勉強を始める前の僕のLinuxのスキルとしては、↓こんな感じ。\n Linuxコマンドを使うことができる（調べ方を知っているといったほうがいいでしょうか） 中規模なLinuxサーバーを構築できる 仮想サーバーで何かできる はまってもググってなんとかすることができる 全部独学、ネット記事の見様見真似が多い  たまたまLPICというLinux技術者認定資格があることを知って、これまで独学でやってきたことがレベル3の出題範囲をカバーしてたので、これだったら楽に取れるんじゃね？と思ったのがきっかけです。\nモチベーションを維持できたのは、ぶっちゃけ、会社の資格報奨制度にLPICレベル1～3が対象としてあったから、というのが本音です。\n実際に受験してみて思ったこと 正直、仮想サーバーでいろいろ遊んでいた身としては、LPIC-2より簡単でした。\n勉強期間でいうと、だいたい1日30分～1時間程度で2.5週間かけました。LPIC-2だと倍以上かけているので、凄く楽に感じました。\nLPICとは 「Linux Professional Institute Certification」の略。「エルピック」と発音するらしいです。\nLinuxのスキルを証明するための「中立公正な」資格試験であり、世界標準な資格になっているようです。\n【注意】LPICとLinuCは別物！ 同じLinux技術者認定資格として「LinuC」もあるので注意が必要。主催している団体が違って、LPICは「 LPI日本支部 」、LinuCは「LPI-Japan」となっています。\nIT資格といえば LinuC | Linux技術者認定試験 リナック | LPI-Japan\nもともとLPICだけだったにも関わらずLinuCができた経緯は良く分かりませんが（大人の事情があることは容易に想像できますが）、非常に紛らわしい。\nどうもLinuCは日本にローカライズされた資格を目指しているらしいけど、「Linux」というグローバルな技術要素を何故日本用にローカライズする必要があるのか、甚だ疑問です。\nどっちを取るかは、会社の報償制度やグローバルな資格が欲しいか、といった観点で判断すればいいでしょう。\nLPIC-3 LPIC-3は、エンタープライズレベルのLinuxプロフェッショナル向けに設計されており、業界内でプロフェッショナルな、ディストリビューションに中立なLinux認定レベルを誇っています。\nLPIC-3認定を受けるためには？\nLPIC-1やLPIC-2と異なり、1つ合格するだけでLPIC-3の認定を受けることができます。\n LPIC-3 300：Linux Enterprise Professional 混在環境 LPIC-3 303：Linux Enterprise Professional セキュリティ LPIC-3 304：Linux Enterprise Professional 仮想化とハイアベイラビリティ  もちろん、LPIC-2認定を受けていることが条件です。ただし、受験する順番は決められておらず、例えば「 304 →201→202」と受験しても問題ありません。\n価格が改定され30,000円→15,000円になった 実は2019年5月1日よりLPIC-3の受験料が15,000円に改定されました。これは非常にうれしいことですね。\nてか30,000円って高すぎるよ。\nLPIC-3 304の範囲 公式ホームページから確認できます。\n出題範囲はそこまで広くありませんが、概念を問われる問題が多いので、丸暗記ではなく、基本をしっかりと身に着けておきたいところです。\n受験の準備 受験はCBT方式です。自分で試験日、試験会場を予約する必要があります。\nLPICにアカウント登録する まずは、 https://www.lpi.org/ja/ からアカウントを作りましょう。\n試験日程、試験会場を予約する 受験申込はピアソンVUEから行います。 https://www.pearsonvue.co.jp/ からアカウントを作って、近くの試験場を選択して受験申込をしてしまいましょう。\n勉強法 始めは参考書で一通り覚えて、Ping-tで周回するイメージです。仮想化に関しては実際にやってみて覚えることは出来ますが、 高可用性に関しては環境構築が難しくほぼ丸暗記しました。\n参考書 所謂「黒本」ってやつです。本番の問題も黒本の演習問題と同じような傾向でしたので、対策としてはこれ一冊でも十分過ぎるくらいかもしれません。\n\nPing-t ほぼ Ping-t で勉強してました。304のコンテンツ利用は有料になっています。6ヵ月利用で5,000円程度だったかと思います。\nhttps://ping-t.com/\n受験までに全ての問題を金にしました。\n周回していると問題を見るだけで答えが分かってしまうので本質的ではありません。そこは解説を隅まで理解するようにして、注意しながらやってました。\n高可用性に関しては丸暗記した LPIC-1、LPIC-2までは実際にLinux環境を構築してコマンドをたたいて体で覚えることはできました。\nLPIC-3 304に関して、仮想化に関してはホストOSがLinuxな環境があれば実際にやってみることが出来るでしょう。ただ、 高可用性に関しては環境構築が難しかったので、試験と割り切って丸暗記しました。\n「試験日」を決めて取り掛かること 受験はCBT方式なので、受験日を自分で決めることができます。 これがメリットでもあり、デメリットでもあります。\n受験日はこの日と決めることで、メリハリある勉強が出来ると思います。\nではでは、頑張ってください。\n","description":"","id":12,"section":"posts","tags":["Linux","LPIC","LPIC-3"],"title":"「祝★LPIC-3認定」LPIC304に合格するために必要なこと","uri":"https://tommylife88.github.io/tommy.dev/posts/2019-08-03-linux-lpic3/"},{"content":"LPIC-2（201、202）試験を受けて、無事一発合格してきました。記念してこれまでの経緯やどう対策してきたかを記事にしたいと思います。\nLPICを取ろうと思った経緯など 勉強を始める前の僕のLinuxのスキルとしては、↓こんな感じ。\n Linuxコマンドを使うことができる（調べ方を知っているといったほうがいいでしょうか） 中規模なLinuxサーバーを構築できる 仮想サーバーで何かできる はまってもググってなんとかすることができる 全部独学、ネット記事の見様見真似が多い  たまたまLPICというLinux技術者認定資格があることを知って、これまで独学でやってきたことがレベル3の出題範囲をカバーしてたので、これだったら楽に取れるんじゃね？と思ったのがきっかけです。\nLinux Professional Institute\nモチベーションを維持できたのは、ぶっちゃけ、会社の資格報奨制度にLPICレベル1～3が対象としてあったから、というのが本音です。\n実際に受験してみて思ったこと 正直、レベル1～3の中でLPIC-2の2つ（201、202）が一番きつかったです。一つ一つの章の難易度が高いうえに、細かなオプションまで問われるので、30歳超えた頭には暗記は苦痛でしかなかったです・・。\n普通Linuxコマンドのオプションなんてmanやコマンドヘルプに頼りますからね。エンジニアとしては、そういう手段だけを知っていればいいはずです。\nあと、受験料が1つ15,000円は高い！このプレッシャーは半端なかったです。\nLPICとは 「Linux Professional Institute Certification」の略。「エルピック」と発音するらしいです。\nLinuxのスキルを証明するための「中立公正な」資格試験であり、世界標準な資格になっているようです。\n【注意】LPICとLinuCは別物！ 同じLinux技術者認定資格として「LinuC」もあるので注意が必要。主催している団体が違って、LPICは「 LPI日本支部 」、LinuCは「LPI-Japan」となっています。\nIT資格といえば LinuC | Linux技術者認定試験 リナック | LPI-Japan\nもともとLPICだけだったにも関わらずLinuCができた経緯は良く分かりませんが（大人の事情があることは容易に想像できますが）、非常に紛らわしい。\nどうもLinuCは日本にローカライズされた資格を目指しているらしいけど、「Linux」というグローバルな技術要素を何故日本用にローカライズする必要があるのか、甚だ疑問です。\nどっちを取るかは、会社の報償制度やグローバルな資格が欲しいか、といった観点で判断すればいいでしょう。\nLPIC-2 中小規模のサーバー、ネットワークを管理するスキルが問われます。出題範囲はかなり広く、また細かなオプションまで問われます。サービスやコマンドによっては似て非なるオプションが存在するので、暗記力も問われます。そもそも暗記は技術の本質から外れてしまいそうだけど、試験だから割り切ってしまいましょう。\nバージョンによって出題範囲や各テーマの重みが変わってくるので、以下の公式ホームページを必ず確認しましょう。\nLPIC-2: Linux Engineerwww.lpi.org\nLPIC-2認定を受けるためには？ LPIC201試験及び202試験に合格すること、かつLPIC-1認定を受けていることが条件です。ただし、受験する順番は決められておらず、例えば「201→202→101→102」と受験しても問題ありません。（ちなみに僕はこのパターンです）\nこの場合、102合格時にLPIC-1とLPIC-2の同時認定となります。\nLPIC-2の範囲 公式ホームページから確認できます。見ての通り、出題範囲が広く、１つ１つの難易度も高いです。\n気を引き締めて勉強しましょう。\n受験の準備 受験はCBT方式です。自分で試験日、試験会場を予約する必要があります。\nLPICにアカウント登録する まずは、 https://www.lpi.org/ja/ からアカウントを作りましょう。\n試験日程、試験会場を予約する 受験申込はピアソンVUEから行います。 https://www.pearsonvue.co.jp/ からアカウントを作って、近くの試験場を選択して受験申込をしてしまいましょう。\n勉強法 始めは参考書で一通り覚えて、Ping-tで周回するイメージです。あとは実際にコマンドをたたいて体に覚えさせることも重要視してました。\n参考書 所謂「茶本」ってやつです。参考書はこれしか触ってません。\n\nPing-t 7割くらいは Ping-t で勉強してました。202、202のコンテンツ利用は有料になっています。6ヵ月利用で5,000円程度だったかと思います。\nhttps://ping-t.com/\n受験までに全ての問題を金にしました。\n周回していると問題を見るだけで答えが分かってしまうので本質的ではありません。そこは解説を隅まで理解するようにして、注意しながらやってました。\n実際に動かしてみる これが一番効果的だと思います。正直、LPIC-2にもなると暗記だけで対策するのは厳しいです。\n仮想マシンでLinuxサーバーをたてて一通りのコマンドを実行してみるのがよいでしょう。\n「試験日」を決めて取り掛かること 受験はCBT方式なので、受験日を自分で決めることができます。 これがメリットでもあり、デメリットでもあります。\n受験日はこの日と決めることで、メリハリある勉強が出来ると思います。\nではでは、頑張ってください。\n","description":"","id":13,"section":"posts","tags":["Linux","LPIC","LPIC-2"],"title":"「祝★LPIC-2認定」LPIC201,202に合格するために必要なこと","uri":"https://tommylife88.github.io/tommy.dev/posts/2019-08-02-linux-lpic2/"},{"content":"仕事でいまだに業務のノウハウとかをExcelファイルで管理してませんか？\nいちいちくそ重いExcelを起動して、セルを方眼紙みたくして、さらには手書きで変更履歴を書いて・・・考えるだけで鬱です。\nもうそんな運用はやめて、超快適なWikiプラットフォームを導入してWEBベースでノウハウを蓄積しよう。\n今回インストールするのは Growi になります。こちらはオープンソースソフトウェアでブラウザベースで動作します。\nMarkdownに対応しており、リアルタイムプレビュー機能付きなのでライティング、リライティングは爆速です。もちろん複数人OK、変更履歴も管理してくれます。\n開発はとても賑わっているようです。（→ Growi GitHub）ありがたや。\nただインストールするだけなら面白くないので、今回は仮想環境上で作っちゃいます。仮想環境はVagrant＋VirtuaBox。Vagrantとかの詳しい話は割愛します。\nうまくいけば、ホストPCが変更になってもWikiの移設が簡単簡単。\n構築したときの環境 筆者の環境\n ホストPC：Windows 10 Home（64bit）  CPU：Intel Core i7-7700HQ RAM：16GB Vagrant 2.2.3 VirtualBox 6.0.4   ゲストPC（仮想PC）：Ubuntu 18.04.2 LTS（bento/ubuntu-18.04）  Docker 18.09.2 docker-compose 1.24.0-rc1    ※ホストPCだが、サーバー用途ならWindowsじゃなくてLinux系OSのほうが絶対良い。\n仮想環境を整える 公式に従い、ホストPCにVagrantインストール\nhttps://www.vagrantup.com/downloads\n公式に従い、ホストPCにVirtualBoxインストール\nhttps://www.virtualbox.org/wiki/Downloads\nVagrant＋VirtualBoxでゲストPC（仮想PC）を作る ホストPCでコマンドプロンプトを起動し、vagrant boxイメージを生成します。\nここでは作業ディレクトリとしてDドライブのvagrantフォルダにgrowiフォルダを作ることにする。\n1 2 3 4 5  D:\\vagrant\u0026gt; mkdir growi D:\\vagrant\u0026gt; cd growi D:\\vagrant\\growi\u0026gt; vagrant init bento/ubuntu-18.04 D:\\vagrant\\growi\u0026gt; vagrant up D:\\vagrant\\growi\u0026gt; vagrant ssh   自動生成されたVagrantファイルは後で弄る。\nゲストPCにSSHでログインできればOK。\nゲストPCの環境設定 ここからはゲストPC側の設定です。\nパッケージの最新化と日本語環境、タイムゾーン設定を行う。 1 2 3 4 5 6 7 8 9 10 11 12  vagrant@vagrant:~$ sudo apt update \u0026amp;\u0026amp; sudo apt upgrade -y vagrant@vagrant:~$ sudo locale-gen ja_JP.UTF-8 vagrant@vagrant:~$ sudo localectl set-locale LANG=ja_JP.UTF-8 LANGUAGE=\u0026#34;ja_JP:ja\u0026#34; vagrant@vagrant:~$ exit #いったんゲストPCから抜ける D:\\vagrant\\growi\u0026gt; vagrant ssh vagrant@vagrant:~$ echo $LANG ja_JP.UTF-8 vagrant@vagrant:~$ sudo dpkg-reconfigure tzdata #[アジア]-[東京]を選択しましょう vagrant@vagrant:~$ exit #いったんゲストPCから抜ける D:\\vagrant\\growi\u0026gt; vagrant reload #ゲストPCを再起動 D:\\vagrant\\growi\u0026gt; vagrant ssh   ゲストPCに Docker インストール 公式に従い、Dockerをインストールする。\nhttps://docs.docker.com/engine/install/\n1 2 3 4 5 6 7 8  vagrant@vagrant:~$ curl -fsSL https://get.docker.com/ | sudo sh vagrant@vagrant:~$ docker -v Docker version 18.06.2-ce, build 6d37f41 vagrant@vagrant:~$ sudo usermod -aG docker $USER #root権限なしで実行する vagrant@vagrant:~$ exit #いったんゲストPCから抜ける D:\\vagrant\\growi\u0026gt; vagrant ssh vagrant@vagrant:~$ groups #dockerに所属していることを確認する   ゲストPCに Docker Compose インストール 公式に従い、Docker Composeをインストールする。\nhttp://docs.docker.jp/compose/install.html\n1 2 3 4  vagrant@vagrant:~$ sudo curl -L https://github.com/docker/compose/releases/download/1.24.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose vagrant@vagrant:~$ sudo chmod +x /usr/local/bin/docker-compose vagrant@vagrant:~$ docker-compose -v docker-compose version 1.24.0-rc1, build 0f3d4dda   ゲストPCに Growi インストール お持たせしました！ようやく「Growi」をインストールします。\nといってもコマンド一発でDockerさんがイイ感じにしれくれます。\nGitHubにある手順に従い、Growiをインストールする。\nhttps://github.com/weseek/growi-docker-compose\nホストPCからゲストPCにアクセスできるよう、docker-compose.ymlのportsを変更しておきます。\n1 2 3  vagrant@vagrant:~$ git clone https://github.com/weseek/growi-docker-compose.git growi vagrant@vagrant:~$ cd growi vagrant@vagrant:~$ vi docker-compose.yml   弄るのは１行だけ。\n1 2 3  ports:#- 127.0.0.1:3000:3000 # localhost only by default- 3000:3000# ← modified  アプリをビルドします。\n1 2 3 4  vagrant@vagrant:~$ docker-compose up #ひたすらログが流れて app_1 ・・・ : [production] Express server is listening on port 3000 #↑が表示されれば完了した   完了後、http://localhost:3000にアクセスするとGrowiのセットアップ画面が表示されるはず・・。がアクセスできません。\nVagrantのポートフォワードの設定が忘れてましたね。\nこのアプリはデフォルトで3000番ポートで待ち受けているようですので、ホストPCの12345番ポート（ここは任意）をゲストPCの3000番ポートにポートフォワード設定させます。\nCtrl+Cでアプリを止め、ゲストPCを抜けVagrantfileを弄ります。\nVagrantfileはこうなりました。こちらは超最小限の設定です。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71  # -*- mode: ruby -*- # vi: set ft=ruby : # All Vagrant configuration is done below. The \u0026#34;2\u0026#34; in Vagrant.configure # configures the configuration version (we support older styles for # backwards compatibility). Please don\u0026#39;t change it unless you know what # you\u0026#39;re doing. Vagrant.configure(\u0026#34;2\u0026#34;) do |config| # The most common configuration options are documented and commented below. # For a complete reference, please see the online documentation at # https://docs.vagrantup.com. # Every Vagrant development environment requires a box. You can search for # boxes at https://vagrantcloud.com/search. config.vm.box = \u0026#34;bento/ubuntu-18.04\u0026#34; # Disable automatic box update checking. If you disable this, then # boxes will only be checked for updates when the user runs # `vagrant box outdated`. This is not recommended. # config.vm.box_check_update = false # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine. In the example below, # accessing \u0026#34;localhost:8080\u0026#34; will access port 80 on the guest machine. # NOTE: This will enable public access to the opened port # config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 80, host: 8080 config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 3000, host: 12345 # Create a forwarded port mapping which allows access to a specific port # within the machine from a port on the host machine and only allow access # via 127.0.0.1 to disable public access # config.vm.network \u0026#34;forwarded_port\u0026#34;, guest: 80, host: 8080, host_ip: \u0026#34;127.0.0.1\u0026#34; # Create a private network, which allows host-only access to the machine # using a specific IP. # config.vm.network \u0026#34;private_network\u0026#34;, ip: \u0026#34;192.168.33.10\u0026#34; # Create a public network, which generally matched to bridged network. # Bridged networks make the machine appear as another physical device on # your network. # config.vm.network \u0026#34;public_network\u0026#34; # Share an additional folder to the guest VM. The first argument is # the path on the host to the actual folder. The second argument is # the path on the guest to mount the folder. And the optional third # argument is a set of non-required options. # config.vm.synced_folder \u0026#34;../data\u0026#34;, \u0026#34;/vagrant_data\u0026#34; # Provider-specific configuration so you can fine-tune various # backing providers for Vagrant. These expose provider-specific options. # Example for VirtualBox: # # config.vm.provider \u0026#34;virtualbox\u0026#34; do |vb| # # Display the VirtualBox GUI when booting the machine # vb.gui = true # # # Customize the amount of memory on the VM: # vb.memory = \u0026#34;1024\u0026#34; # end # # View the documentation for the provider you are using for more # information on available options. # Enable provisioning with a shell script. Additional provisioners such as # Puppet, Chef, Ansible, Salt, and Docker are also available. Please see the # documentation for more information about their specific syntax and use. # config.vm.provision \u0026#34;shell\u0026#34;, inline: \u0026lt;\u0026lt;-SHELL # apt-get update # apt-get install -y apache2 # SHELL end   ゲストPCを再起動して、再度SSHではいりアプリを起動します。\ndockerイメージはビルド済みなのでstartコマンドでOK。\n1 2 3 4 5 6 7  D:\\vagrant\\growi\u0026gt; vagrant reload D:\\vagrant\\growi\u0026gt; vagrant ssh vagrant@vagrant:~$ cd growi vagrant@vagrant:~$ docker-compose start Starting mongo ... done Starting elasticsearch ... done Starting app ... done   http://localhost:12345でセットアップ画面が表示されましたね。\nLAN内の他のPCからも、http://[ホストPCのIPアドレス]:12345でアクセス可能になっているはずです。\nlocalhostではOKで、外部からのIP指定でダメならホストPCのファイアウォールとかの設定が怪しいかも、ここでは割愛します。\nそもそもサーバー用途ならWindowsはおすすめしないです・・。\nではでは、良いGrowiライフを！\n","description":"","id":14,"section":"posts","tags":["Markdown","Wiki","vagrant","docker","docker-compose"],"title":"「超簡単」仮想環境でWiki「GROWI」を導入する（Markdown対応）","uri":"https://tommylife88.github.io/tommy.dev/posts/2018-12-13-growi-on-docker-on-vagrant/"},{"content":"こんな人に読んでほしい。\n Linux開発に触れてみたい Linux開発始めたいけど、いまいち何から手をつけたらいいか分からない  Linuxのコマンドをデバッグしてみよう。\nコマンドのパッケージを特定してソースコードを落としてビルドしてデバックするところまでを実践的に触れることができると思う。\nlsコマンドをデバッグしてみる 本記事ではLinuxでよく使うコマンドlsをソースコートを落としてビルド、デバッグまでやってみる。\n環境 1 2 3 4 5  $ cat /etc/lsb-release DISTRIB_ID=Ubuntu DISTRIB_RELEASE=18.04 DISTRIB_CODENAME=bionic DISTRIB_DESCRIPTION=\u0026#34;Ubuntu 18.04.1 LTS\u0026#34;   コマンドのパッケージを特定 まずは、lsコマンドのパッケージを特定します。\n1 2 3 4  $ which ls /bin/ls $ dpkg -S /bin/ls coreutils: /bin/ls   lsは oreutilsっていうパッケージに含まれていることが分かりました。\nパッケージのソースをダウンロード ubuntu の公式パッケージであればapt sourceでソースコードをダウンロードできます。\nリポジトリからソースをダウンロードするため、sources.listのdeb-srcを有効にします。\n1 2  $ sudo su -c \u0026#34;grep \u0026#39;^deb \u0026#39; /etc/apt/sources.list | \\ sed \u0026#39;s/^deb/deb-src/g\u0026#39; \u0026gt; /etc/apt/sources.list.d/deb-src.list\u0026#34;   リポジトリを更新しパッケージをダウンロードします。\n1 2  $ sudo apt update $ apt source coreutils   lsをビルドする環境を整える apt build-depでソースパッケージをビルドするのに必要なソフトウェアをインストールしてくれます。便利。\n1 2  $ sudo apt install build-essential $ sudo apt build-dep coreutils   ビルドする デバッグしたいので、デバッグ情報付加、最適化しないようにします。\n1 2 3  $ cd coreutils-8.28 $ ./configure CFLAGS=\u0026#34;-g3 -O0\u0026#34; $ make   srcディレクトリ配下に実行ファイルが生成されます。\nデバッグする GNUデバッガgdbを使います。$ gdb (実行ファイル名)で起動します。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  $ cd src $ gdb ./ls (gdb) b main #main()関数にブレークポイントを貼る Breakpoint 1 at 0x4fc5: file src/ls.c, line 1445. (gdb) r #実行する Starting program: /home/coreutils-8.28/src/ls [Thread debugging using libthread_db enabled] Using host libthread_db library \u0026#34;/lib/x86_64-linux-gnu/libthread_db.so.1\u0026#34;. Breakpoint 1, main (argc=1, argv=0x7fffffffe388) at src/ls.c:1445 1445 { (gdb) n #ステップ実行する 1451 set_program_name (argv[0]); (gdb) 1452 setlocale (LC_ALL, \u0026#34;\u0026#34;); (gdb) 1453 bindtextdomain (PACKAGE, LOCALEDIR);   main()関数にブレークポイントを貼ってステップ実行している（デバッグしている）例です。gdbの使い方に関してはマニュアルを参照しましょう。\nどうでしょう？たったこれだけですが、Linux開発の基本的なところである、「パッケージのソースを落としてビルド環境整えて、ビルド、デバッグする」という部分に触れることができましたね。\n","description":"","id":15,"section":"posts","tags":["Linux","gdb"],"title":"「Linuxに触れる」パッケージのソースを落としてビルド、デバッグする方法","uri":"https://tommylife88.github.io/tommy.dev/posts/2018-10-11-linux-debug-package/"},{"content":"本番環境のWordPressでテーマやCSS、プラグインを編集するには勇気がいるものです。\nそこでローカル環境にいま動いているWordPressを複製して、ローカル環境で気兼ねなくテストできる環境を作っておきましょう。\nローカル環境は「Local By Flywheel」で構築します。\nローカル環境にWordPress環境を構築する方法\nを参考にして下さい。\n本番環境→ローカル環境に複製する手順としては、\n本番環境をバックアップとってエクスポートする ローカル環境にインポートする  だけなのですが、「All-in-One WP Migration」というプラグインを使うことで簡単に実現できます。\nhttps://ja.wordpress.org/plugins/all-in-one-wp-migration/\n「All-in-One WP Migration」による複環境製を行う 管理画面のプラグインの「新規追加」の画面にいって、「All-in-One WP Migration」をインストールし、有効化します。\n本番環境のバックアップ／エクスポートする 「All-in-One WP Migration」のバックアップ画面を表示します。\nこちらのプラグインですが、無料版だとインポート時の容量に512MBのサイズ制限がかかります。\n（有料版にアップグレードすることで無制限になるようです）\nメディアライブラリ内のデータ（アップロードしたデータ）をバックアップするとあっという間にサイズ制限を超えるので、メディアライブラリを対象から外しておきます。\nちょっとめんどくさいですが、メディアライブラリ内のデータはサーバーからFTPでダウンロードしましょう。\nただ、メディアライブラリに関しては、ローカル環境にインポートしなくても。画像が表示されないだけなので、基本的なサイトの動作には影響ないでしょう。\n「ファイル」を選択するとエクスポートが始まります。\nしばらく待ちましょう。\n完了したらダウンロードします。\nメディアライブラリを除外しても512MBを超えるようであれば、素直に有料版にしたほうが良いかもしれません。\nそれくらい便利なプラグインだと思います。\nローカル環境にインポートする 「Local By Flywheel」でローカル環境に構築したWordPressにインポートします。\nローカル環境のWordPressにも同じくプラグイン「All-in-One WP Migration」をインストールしておきます。\n「All-in-One WP Migration」のインポート画面を表示します。\n「ファイル」を選択して、指示通りにすすめていきます。\nアップロードサイズ制限に引っかかる場合、 最大アップロードファイルサイズを上げる方法 を参考にしましょう。\nしばらく待ちます。\nインポートが完了後、パーマリンクを更新します。\nデータベースの更新を行い完了です。\nログイン画面が表示されるはずですので、本番環境のIDとパスワードを入力しましょう。\nなお、メディアライブラリは、\\public\\wp-content\\uploads（ローカル環境のWordPressフォルダ）配下にアップロードされるので、本番環境からFTPでとってきたファイルをローカルのパスにコピーすることで画像を表示できます。\nまとめ どうでしょうか。超簡単ですよね。\nこれで本番環境と同じ環境をローカルで試すことができます。\n","description":"","id":16,"section":"posts","tags":["WordPress"],"title":"WordPress本番環境をローカル環境にコピー（複製）する方法","uri":"https://tommylife88.github.io/tommy.dev/posts/2018-03-02-wp-copy-to-local-env/"},{"content":"WordPressのバージョン4.x系から5.x系にバージョンアップする際に、今動いているサイト（テーマやプラグインいろいろ）がちゃんと動作するか？が一番の心配事になります。\n問題ないと言い切れるのならさっさと上げたいけど、サイトが止まると収益に影響するからなかなか踏み切れないんだよね。\nそこで今回、本番環境をローカル環境に複製して、ローカル環境でWordPress 5.Xの動作確認をしようというわけ。\n本記事では、 ローカル環境にWordPressを立ち上げる ところまで紹介します。\n超簡単です。\nLocal を使ったWordPress環境 WordPressのローカル環境を構築するのに使用するツールが「Local by Flywheel」になります。\nWindows上に仮想環境（VirtualBox）を作成して、仮想環境上でWordPressを動かす、ということをやってくれるアプリケーションです。\n仮想環境と聞くとなんやら小難しいかもしれませんが、ユーザーはアプリを介して操作するため直感的に操作できます。\nLocal インストール https://localwp.com/\n「FREE DOWNLOAD」を選択する。\n必要事項、\n OS「Windows」を選択する（MACなら「MAC」） Work Email Number of website  を入力し、「GET IT NOW!」でインストーラーをダウンロード開始。\n完了後、実行ファイルを実行しインストールを開始する。\n途中、VirtualBoxによるユーザーアカウント制御画面が何回か表示されるが、全て許可する。\nローカル環境にWordPress環境を構築する 「Local by Flywheel」を起動して、環境を作っていきます。\nといってもポチポチしていくだけ。\n仮想環境を構築する 「LET’S GO!」をクリックする。\nWordPressの環境設定を行う 「CREATE A NEW SITE」をクリックする。\nサイト名を入力し「CONTINUE」をクリックする。\nサイト名は好きなように。\n「ADVANCED OPTIONS」でパスを設定しておくとよい。\nPHP、MySQLのバージョンを選択する。\nこちらはサーバーに合わせて選択する。\n分からなければデフォルト（Preferred）としておく。\nこちらは後で変更可能となってます。\nユーザー名、パスワードを入力し「ADD SITE」をクリックする。\nユーザー名、パスワードは管理者画面にログインするときに使うので覚えておく。\nなんでもよい。\nしばらくすると、HOME画面が表示されます。\nこれでWordPress環境は立ち上がってます。\nバージョンもしっかり5.Xですね。\nWordPressの管理者画面にログインする 「ADMIN」をクリックします。\n「Microsoft Edge」では表示されませんでした。\n「Google Chrome」では問題ないので、「Google Chrome」で開きましょう。 サイトを表示する 「VIEW SITE」をクリックします。\n「Microsoft Edge」では表示されませんでした。\n「Google Chrome」では問題ないので、「Google Chrome」で開きましょう。 WordPressの仮想環境を止める 仮想環境を止めたければ「STOP SIE」をクリックします。\nまとめ ローカル環境が整ったことで、いろいろ試行錯誤できるようになりました。\n次はいま動いている本番環境のWordPressをローカル環境にコピーします。\n","description":"","id":17,"section":"posts","tags":["WordPress","Local"],"title":"ローカル環境にWordPress環境を構築する方法","uri":"https://tommylife88.github.io/tommy.dev/posts/2018-03-01-wp-setup-local/"}]